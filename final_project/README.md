# The Hateful Memes Multimodal approach
<img src="./img/daters.fig" />

The Hateful Memes Challenge is a dataset and benchmark created by Facebook AI to drive and measure progress on multimodal reasoning and understanding. In this model we will compare the multimodal and the unimodal aproach and the effectivity in the multimodal approach.

# Meme sentiment definition

Take an image, add some text: you've got a meme. Internet memes are often harmless and sometimes hilarious. However, by using certain types of images, text, or combinations of each of these data modalities, the seemingly non-hateful meme becomes a multimodal type of hate speech, a hateful meme.

At the massive scale of the internet, the task of detecting multimodal hate is both extremely important and particularly difficult. As the illustrative memes above show, relying on just text or just images to determine whether or not a meme is hateful is insufficient.

The owner of the data (Facebook) team defines hate speech as:

A direct or indirect attack on people based on characteristics, including ethnicity, race, nationality, immigration status, religion, caste, sex, gender identity, sexual orientation, and disability or disease. We define attack as violent or dehumanizing (comparing people to non-human things, e.g. animals) speech, statements of inferiority, and calls for exclusion or segregation. Mocking hate crime is also considered hate speech.

# Meme datasets
The input data contains the following files:

license.txt - the data set license
README.md - the data set readme
img/ - the directory of PNG images
train.jsonl - the training set
dev.jsonl - the development set
test.jsonl - the test set

*Image is a compilation of assets, including Â©Getty Image.*

All the information about the dataset and the challenge can be found in: https://ai.facebook.com/blog/hateful-memes-challenge-and-data-set

